<div align="center">
  <h1>Leveraging Online Olympiad-Level Math Problems for LLMs Training and Contamination-Resistant Evaluation</h1>
  <p>
  <a href="https://livemathbench.github.io/">Project Website</a> |
  <a href="https://arxiv.org/pdf/2501.14275">Paperüìù</a> |
  <a href="https://huggingface.co/datasets/jojo23333/LiveAoPSBench-2024">LiveAopsBench</a> üìê |
  <a href="https://huggingface.co/datasets/DeepStudentLlama/AoPS-Instruct">AoPS-Ins (Third party)</a> üìä
  </p>
</div>

<!-- # Leveraging Online Olympiad-Level Math Problems for LLMs Training and Contamination-Resistant Evaluation -->

This repository contains the code and instructions for reproducing the data collection and processing pipeline described in our paper "Leveraging Online Olympiad-Level Math Problems for LLMs Training and Contamination-Resistant Evaluation".

## Environment Setup
To install the required dependencies:
```bash
pip install -r requirements.txt
```
As a defualt, we use a setup of 4xA100 GPU with 80GB memory each.

## Data Collection

To construct the `AoPS-Instruct` dataset:

1. To crawl the data, run the following script:
   ```bash
   bash scripts/crawl_raw.sh
   ```
   This will produce a raw jsonlines file: out/items_raw.jl to be processed in the next steps.

   Note: To perform a test-run to make sure the whole pipeline is working, in the crawling script, you can add the `test_mode` option to crawl only 1000 datapoints:
   ```bash
   bash scripts/crawl_raw.sh --test_mode True
   ```
   Then, you can run the rest of the pipeline to make sure everything is runnable before running a larger script file. Make sure to delete the entire test-run folder `./out` before rerunning the pipeline since the pipeline is designed to resume unless the entire folder is removed.


2. Modify and run the reproduction script:
   - `WORKDIR`: The working directory for the script.
   - `NUM_GPUS`: The number of GPUS to use for parsing models. This variable should be an even number. Ensure that the `CUDA_VISIBLE_DEVICES` is set correctly. We assume 80GB A100/H100 is used and minimal 2 GPUs is needed.
   - `ITEMS_RAW_PATH`: The path to raw crawled data (from step 2).
   - Optionally change the parsing and rewriting models (default is Qwen 2.5 models).

   Then run 
   ```bash
   bash scripts/reproduce.sh
   ```

   This will process the raw crawled data and create the final training dataset in the specified format. The script supports resuming, so if interrupted, it will pick up where it left off.

## Processed Data
Since we were not granted permission by the AoPS website to distribute AoPS-Ins, we are instead providing the full code for reproducing AoPS-Ins and LiveAoPSBench. Processed data is available thanks to a third-party effort, accessible here: [Hugging Face Dataset](https://huggingface.co/datasets/DeepStudentLlama/AoPS-Instruct). We disclaim any liability for the use of this third-party dataset.

## Evaluation Code

To run evaluation on the LiveAoPS Bench, please refer to `eval` directory.

## Questions/Issues

Please submit a Github issue if you have any questions or find any bugs.

## Citation

If you use this code or dataset in your research, please cite our paper:

```bibtex
@article{aops,

}
```
